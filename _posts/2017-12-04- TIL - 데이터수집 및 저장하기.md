---
layout:            post
title:             "17/12/04 - data analysis - 데이터 수집 및 저장하기"
menutitle:         "17/12/04 - data analysis - 데이터 수집 및 저장하기"
category:          data analysis
author:            myohyun
tags:              python
---

(* 파이썬을 활용한 데이터 길들이기 책 요약.)

# 6장-데이터 수집 및 저장하기

**GOAL:**

1. 데이터를 어디에 저장하고 미래의 필요에 대비해 보관할 수 있는지 알아본다.
2. 데이터 랭글링(?)문제와 이와 관련된 자동화된 해결책을 살펴보며 데이터의 좋고 나쁨을 판단한다
3. 데이터의 가능성을 타진해 보기 위해 사용될 수 있는 도구들에 대해 배운다.



살펴볼 가치가 있느 데이터셋을 찾아내기 위해 시간을 투자해야 한다.

**살펴볼 가치가 있다?**

- 질문과 관련된 데이터세트가 존재할 만큼 구체적이어야 함
- 자신을 포함한 많은 사람의 흥미를 유발할 수 있을 정도로 광범위한 질문

**데이터의 조건 **

- 데이터의 출처가 분명하며 신뢰할 수 있어야 함

- 데이터가 유효한가?

- 최신데이터인가?

- 앞으로 혹은 현재까지의 업데이트와 발행물을 신뢰할 수 있는가?



**아래의 질문 중에 적어도 3개에 **yes **라고 할 수 있으면 잘 하고 있는것! **

**두 개 이상의 질문에 **no **라고 답한다면 좀 더 신뢰할 수 있는 데이터를 찾아야 한다.**

- 데이터와 관련한 질문이나 문제가 생겼을 때 데이터 저자에게 문의하여 적절한 답을 얻을 수 있는가?
- 데이터가 정기적으로 갱신되고 오류가 체크되고 있는가?
- 데이터 수집 방법과 수집 과정에서 사용된 샘플에 대해 명시되었는가?
- 데이터 세트를 확인하고 입증해 줄 수 있는 다른 출처의 데이터가 존재하는가?
- 주제와 관련된 본인의 지식으로 비추어 보아 데이터가 타당해 보이는가?

## 사실확인

데이터의 유효성 입증 위해 

- 데이터 출처에 연락을 취하여 새로운 방식이나 최근 발표된 내용이 있는지 확인한다
- 현재 데이터 출처와 비교 대상이 될 만한 다른 좋은 출처를 파악한다
- 전문가와 연락하여 좋은 데이터 출처와 신뢰할 만한 정보를 알아낸다
- 연구 주제에 대한 심도있는 조사를 통해 데이터 출처 및 데이터세트의 신뢰성을 판단

도서관 및 정부기관, 학교,

구글검색(온라인에 게재된 내용을 검토할 땐 항상 신중해야 한다. 출처가 정확한가? 주장이 설득력 있고 앞뒤가 맞는가? 주장이 타당한 증거로 뒷받침 되었는가? 이와 같은 질문들을 염두에 두고 검색 결과를 평가한다)

## 가독성, 깔끔함 그리고 데이터의 지속성

- 데이터가 더러워도 클리닝할 수 있음(7장)

- 어떤 데이터가 읽기 어렵다는 것은 보통 데이터 출처(데이터베이스)의 상태가 좋지 않다는 것을 의미

- 데이터가 클리닝 여부 조사 필요(만든 이에게 문의)

  - 데이터가 얼마나 정리되었나?

  - 데이터의 **통계적 오차율** 이 추정되었나? 잘못 입력된 데이터 입력값이나 잘못 보고된 데이터가 수정되었나?

  - 이후 업데이트 될 데이터를 수집할 수 있나?

  - 데이터 수집 과정에서 사용된 방법은 무엇이며 입증된 방법인가?

>엄격한 방법에 의해 조사/수집되었으며 표준화된 데이터의 경우, 데이터를 쿨리닝하고 결과를 보고하기 위한 스크립트를 일단 작성해 놓으면 이후에는 약간씩만 수정하여 재사용할 수 있다. 데이터의 시스템에 변화를 주는 것은 비용과 시간이 많이 드는 작업이라 자주 변경되지 않기 때문이다. 한번 데이터 클리닝 스크립트를 작성해 놓으면 새로 수집하게 될 데이터를 쉽게 처리할 수 있기 때문에 데이터 분석에 집중할 수 있다.

데이터를 어디서 구할 수 있을까?
- 전화걸기(데이더 제공 단체/사람에게 문의)
- 미 정부 데이터 (한국도 있지) - 교육데이터, 선거 결과, 인구 통계, 환경 데이터, 노동 통계
- 전 세계 정부 및 도시 오픈 데이터(책 참조)
>정부 데이터에 대해서도 사실 확인이 필요하다. 인권 침해부분도 있을 수 있고..문의사항이 있다면 주저없이 물어보자

- 조직 및 비정부조직(NGO) 데이터
- 교육 및 대학 데이터
- 의료 및 과학 데이터
- 크라우드 소싱 데이터 및 API (인터넷 상의 포럼, 서비스, 소셜 미디어 등)  보통 API 로 데이터에 접근 (내가 쓰려는 것)

| 장점                                       | 단점                                   |
| ---------------------------------------- | ------------------------------------ |
| 사용 가능한 데이터에 대한 즉각적인 접근                   | 대규모 API 에 대한 신뢰성 부족(선택 편향)           |
| 막대한 양의 데이터                               | 데이터 과부하                              |
| 해당 서비스의 데이터 보관 장소에 접근하면 되기 때문에 데이터 저장에 대해 신경쓸 필요 없음 | 데이터 접근의 신뢰성 및 의존성 문제(API 제한 및 고장 시간) |

- 그 외 다양한 웹사이트를 통해 연구 질문이나 아이디어를 공유/ 크라우드소싱을 통해 그에 대한 답을 얻을 수 있음
- 연구 주제와 관련된 전문가 포럼에 방문하거나 직접 설문조사를 게시하고 유통하는 채널을 만들 수도 있음
- 본인이 직접 연구 질문을 생각하고 방법론을 개발했다면 이와 관련하여 데이터 크기와 표본 오차를 보고해야 한다(위스콘신 대학교의 솔문조사 길잡이 참고)

## 사례 연구: 데이터 예시 조사

- 내가 관심있어 하는 주제에 대해 검색과 조사를 통해 어떻게 문제를 찾아낸는지 예시를 들어줬음(책 참고)

## 데이터 저장하기 :언제, 왜, 어떻게?

## 데이터베이스 

- 관계형 : mySql, PostgreSQL
- 비관계형: Mongodb
- SQLite: 간단한 프로젝트에 적합
- Dataset:  받아온 데이터를 그대로  DB 에 넣을 수 있게 함. 데이터베이스 Wrapepr

## 데이터 저장방법

- 드롭박스, 클라우드 서버
- 계층적 데이터 형식(hierarchical data format, HDF)  데이터솔루션
- 하둡 - 대용량 데이터 분산 저장 시스템
