---
layout:            post
title:             "17/11/22- TIL - Logistic regression"
enutitle:          "17/11/22- TIL - Logistic regression"
category:          Machine learning
author:            myohyun
tags:              Machine learning
---
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML'></script>

[[TOC]]

# 로지스틱 회귀 Logistic regression

|  | 로지스틱 회귀 Logistic regression |
|--------|--------|
| <b>수집       |모든 방법        |
| <b>준비       |구조적인 데이터 형태가 좋음.(수치형 값은 거리를 계산하는 데 필요)        |
| <b>분석       |모든 방법        |
| <b>훈련       |훈련하는 데 대부분의 시간을 보내며, <br>이 단계에서 데이터를 분류하기 위해 최적의 계수 찾음        |
| <b>검사       |훈련 단계를 마치고 나면 분류는 빠르고 쉽게 진행됨        |
| <b>사용       |이 응용 프로그램은 양간의 입력 데이터가 있어야 함<br>1. 수치형으로 구성된 값을 출력<br>2. 응용 프로그램은 입력 데이터에 간단한 회귀 계산을 적용<br>3. 입력 데이터가 속하는 분류 학목을 결정함<br>또한,응용 프로그램은 계산된 분류 항목에서 몇 가지 동작을 수행함|
| <b>장점       |1. 계산 비용이 적다.<br>2. 구현하기 쉽다<br>3. 결과 해석을 위한 지식 표현이 쉽다        |
| <b>단점       |2. 언더피팅(underfitting)경향이 있어, 정확도가 낮게 나올 수 있음        |
| <b>활용       |3. 수치형 값, 명목형 값        |



? 두 개 이상의 분류가 가능한가?

## weight 구하기

- 데이터 준비

**데이터 벡터**: $$ x $$ (깃허브 올릴 땐 인라인도 \$\$로 )<br>
**weight**: $$ w $$<br>
**데이터 행렬**: $$ M $$<br>
**데이터 분류값 행렬**: $$ t $$<br>


- weight 구하기
이때 가중치를 구하는 방법은 다양하다. 첫 번째로 weight를 최적화 하기 위해 `gradient method`를 사용해본다.


for loop 안. 반복 횟수를 정해준다.-------------------------<br>

$$ z = x^Tw $$ 를 계산한다.

sigmoid 함수 = $$ \sigma(z) = \frac{1}{1+e^{-z}} $$ 를 이용해 $$ h= \sigma(z) $$를 구한다.
각 데이터 분류값 벡터 $$ c $$ 에서 $$ h $$ 를 빼 `error` 벡터를 구한다.<br>
$$ e = c - h $$

weight를 업데이트한다.<br>
$$ w = w + \alpha M^Te $$
<!-- $$ \sigma(z)> 0.5 $$ 이면 1, $$ \sigma(z) \leq 0.5 $$ 이면 0으로 분류 --> 

for loop-------------------------------------------------------------

계산을 끝낸 $$ w $$ 값으로 의사결정 경계선을 그립니다. 경계선이 두 집합을 잘 분리하는지 확인!<br>

$$
 y= - \frac{w[0]}{w[2]} -\frac{w[1]}{w[2]}x
$$

- ### 결과
<figure>
   <img src="{{ "/media/img/logistic1.png" | absolute_url }}" />
   <figcaption>두 집합을 분류하는 직선을 구함</figcaption>
</figure>


분류는 잘 되었으나, 너무 많은 계산을 하므로 (데이터가 1억, 10억 개 이상 된다면?) 이를 보강하는 방법을 생각해 볼 수 있다. -> 확률적인 기울기 상승법

## 확률 기울기 상승

- 온라인 학습 알고리즘 중 하나. 이런 이름으로 알려져 있는 이유는 모든 데이터를 한꺼번에 처리하지 않고, 새로운 데이터가들어돌 때마다 분류기를 점진적으로 갱신할 수 있기 때문. (데이터를 한꺼번에 처리하는 방법은 일괄 처리(batch processing))
- 한 번에 단 하나의 사례를 사용하여 가중치를 갱신하는 방법
- 위에서 수행한 방법에서 h와 e가 벡터가 아닌 단일값이 된다. 데이터행렬도 벡터로 바뀜.
- w를 없데이트할 때 데이터를 하나 밖에 사용을 안 해서 위의 w보다는 값의 정확도가 떨어진다.

<figure>
   <img src="{{ "/media/img/logistic2.png" | absolute_url }}" />
   <figcaption>두 집합을 분류하는 직선을 구함</figcaption>
</figure>
